{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaddc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# read in dataset\n",
    "df = pd.read_csv('train_classification_v1.csv')\n",
    "\n",
    "# define attributes and target\n",
    "X = df[[column for column in df.columns if column != \"Target\"]]\n",
    "y = df['Target']\n",
    "\n",
    "#Checking shape of X and y\n",
    "print(\"Shape of X is {}, and shape of y is {}\".format(X.shape, y.shape))\n",
    "\n",
    "# Splitting the data between test and train samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)\n",
    "\n",
    "# Creating and training a simple linear regression model\n",
    "logr = LogisticRegression(max_iter=10000)\n",
    "logr.fit(X_train,y_train)\n",
    "\n",
    "# print the score\n",
    "print(\"Score on training set: {:.3f}\".format(logr.score(X_train, y_train)))\n",
    "print(\"Score on test set: {:.3f}\".format(logr.score(X_test, y_test)))\n",
    "\n",
    "# print the coefficient\n",
    "coefficient = logr.coef_\n",
    "\n",
    "\n",
    "odds = np.exp(coefficient)\n",
    "\n",
    "# Cross-validation\n",
    "\n",
    "# Calculating cross-validated R-squared scores \n",
    "simple_scores = cross_val_score(logr, X, y, cv=10, scoring='r2')\n",
    "print(simple_scores)\n",
    "\n",
    "print(\"The average test score is:\", simple_scores.mean())\n",
    "print(\"The standard deviation of the test scores is:\", simple_scores.std())\n",
    "\n",
    "# Set up the parameter grid - what values should we check for the polynomial degree?\n",
    "param_grid = {\n",
    "    'poly_features__degree': [1, 2, 3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create the pipeline with PolynomialFeatures and LinearRegression\n",
    "model = Pipeline([\n",
    "    ('poly_features', PolynomialFeatures()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Set up GridSearchCV with the model and parameter grid\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='r2', n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve and print the scores for each iteration\n",
    "cv_results = grid_search.cv_results_\n",
    "for mean_score, params in zip(cv_results[\"mean_test_score\"], cv_results[\"params\"]):\n",
    "    print(f\"Mean R-squared for {params}: {mean_score}\")\n",
    "\n",
    "# Retrieve the best hyperparameters and the corresponding best estimator\n",
    "best_degree = grid_search.best_params_['poly_features__degree']\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(f\"Best Polynomial Degree: {best_degree}\")\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "test_score = best_model.score(X_test, y_test)\n",
    "print(f\"Test R-squared with best model: {test_score}\")\n",
    "\n",
    "\n",
    "## More complex polynomial regression model \n",
    "#poly = PolynomialFeatures(degree=2)\n",
    "#X_train_poly = poly.fit_transform(X_train)\n",
    "#X_test_poly = poly.fit_transform(X_test)\n",
    "\n",
    "#poly_logr = LogisticRegression()\n",
    "#poly_logr.fit(X_train_poly,y_train)\n",
    "\n",
    "#print(\"Score on training set: {:.3f}\".format(poly_logr.score(X_train_poly, y_train)))\n",
    "#print(\"Score on test set: {:.3f}\".format(poly_logr.score(X_test_poly, y_test)))\n",
    "\n",
    "# Remarque : essai de modèle polynomial mais trop lourd pour ordinateur, n'arrive pas à tourner (\"dead kernel\")\n",
    "#max_iter car sinon convergence n'est pas atteinte. Seulement, le programme est pas mal ralenti"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
