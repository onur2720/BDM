import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
import warnings
from collections import OrderedDict
def plot_value_counts(data, column_name):
    value_counts = data[column_name].value_counts()
    value_counts.plot(kind='bar', color='skyblue', edgecolor='k', linewidth=2)
    plt.xlabel(column_name)
    plt.ylabel('Count')
    plt.title(f'Value Counts of {column_name}')
    plt.show()


# Ignore FutureWarnings
warnings.filterwarnings("ignore", category=FutureWarning)

# Set plot style
plt.style.use('fivethirtyeight')
plt.rcParams['font.size'] = 18
plt.rcParams['patch.edgecolor'] = 'k'

# Increase the maximum number of displayed columns
pd.options.display.max_columns = 150

# Read in data
train = pd.read_csv('./train.csv')
test = pd.read_csv('./test.csv')

# Explore the data
train.head()
test.info()
train.info()

# Visualize the count of unique values in integer columns
train.select_dtypes(np.int64).nunique().value_counts().sort_index().plot.bar(
    color='blue', figsize=(8, 6), edgecolor='k', linewidth=2)
plt.xlabel('Number of Unique Values')
plt.ylabel('Count')
plt.title('Count of Unique Values in Integer Columns')

# Color mapping and poverty levels
colors = OrderedDict({1: 'red', 2: 'orange', 3: 'blue', 4: 'green'})
poverty_mapping = OrderedDict({1: 'extreme', 2: 'moderate', 3: 'vulnerable', 4: 'non vulnerable'})

# Explore float columns using KDE plots
plt.figure(figsize=(20, 16))
for i, col in enumerate(train.select_dtypes('float')):
    ax = plt.subplot(4, 2, i + 1)
    for poverty_level, color in colors.items():
        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(),
                    ax=ax, color=color, label=poverty_mapping[poverty_level])
    plt.title(f'{col.capitalize()} Distribution')
    plt.xlabel(f'{col}')
    plt.ylabel('Density')
plt.subplots_adjust(top=2)

# Mapping for 'yes' and 'no' values to 1 and 0 in certain columns
mapping = {"yes": 1, "no": 0}

# Apply the mapping to both train and test data
for df in [train, test]:
    df['dependency'] = df['Dependency rate'].replace(mapping).astype(np.float64)
    df['years of education of female head of household'] = df['years of education of female head of household'].replace(mapping).astype(np.float64)
    df['years of education of male head of household'] = df['years of education of male head of household'].replace(mapping).astype(np.float64)

# Visualize the distribution of 'dependency', 'edjefa', and 'edjefe' columns
plt.figure(figsize=(16, 12))
for i, col in enumerate(['dependency', 'years of education of female head of household', 'years of education of male head of household']):
    ax = plt.subplot(3, 1, i + 1)
    for poverty_level, color in colors.items():
        sns.kdeplot(train.loc[train['Target'] == poverty_level, col].dropna(),
                    ax=ax, color=color, label=poverty_mapping[poverty_level])
    plt.title(f'{col.capitalize()} Distribution')
    plt.xlabel(f'{col}')
    plt.ylabel('Density')
plt.subplots_adjust(top=2)

# Add null 'Target' column to the test dataset
test['Target'] = np.nan
data = pd.concat([train, test], ignore_index=True)

# Identify heads of households
heads = data.loc[data['=1 if household head'] == 1].copy()

# Labels for training
train_labels = data.loc[(data['Target'].notnull()) & (data['=1 if household head'] == 1), ['Target', 'Household level identifier']]

# Visualize the distribution of poverty levels
label_counts = train_labels['Target'].value_counts().sort_index()
label_counts.plot.bar(figsize=(8, 6), color=colors.values(), edgecolor='k', linewidth=2)
plt.xlabel('Poverty Level')
plt.ylabel('Count')
plt.xticks([x - 1 for x in poverty_mapping.keys()], list(poverty_mapping.values()), rotation=60)
plt.title('Poverty Level Breakdown')

# Identify households where family members do not have the same target
all_equal = train.groupby('Household level identifier')['Target'].apply(lambda x: x.nunique() == 1)
not_equal = all_equal[all_equal != True]
print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))

# Handle households without a head
households_leader = train.groupby('Household level identifier')['=1 if household head'].sum()
households_no_head = train.loc[train['Household level identifier'].isin(households_leader[households_leader == 0].index), :]
print('There are {} households without a head.'.format(households_no_head['Household level identifier'].nunique()))

# Check households without a head and different labels
households_no_head_equal = households_no_head.groupby('Household level identifier')['Target'].apply(lambda x: x.nunique() == 1)
print('{} Households with no head have different labels.'.format(sum(households_no_head_equal == False)))

# Set the correct target label for each household
for household in not_equal.index:
    true_target = int(train[(train['Household level identifier'] == household) & (train['=1 if household head'] == 1.0)]['Target'].iloc[0])
    train.loc[train['Household level identifier'] == household, 'Target'] = true_target

# Check again for households where family members do not have the same target
all_equal = train.groupby('Household level identifier')['Target'].apply(lambda x: x.nunique() == 1)
not_equal = all_equal[all_equal != True]
print('There are {} households where the family members do not all have the same target.'.format(len(not_equal)))

# If individual is over 19 or younger than 7 and missing years behind, set it to 0
data.loc[((data['Age in years'] > 19) | (data['Age in years'] < 7)) & (data['Years behind in school'].isnull()), 'Years behind in school'] = 0

# Add a flag for those between 7 and 19 with a missing value
data['Years behind in school-missing'] = data['Years behind in school'].isnull()

# Calculate and visualize missing values
missing = pd.DataFrame(data.isnull().sum()).rename(columns={0: 'total'})
missing['percent'] = missing['total'] / len(data)
missing.sort_values('percent', ascending=False).head(10).drop('Target')

# Define a function to plot counts of two categoricals
def plot_categoricals(x, y, data, annotate=True):
    raw_counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize=False))
    raw_counts = raw_counts.rename(columns={x: 'raw_count'})
    counts = pd.DataFrame(data.groupby(y)[x].value_counts(normalize=True))
    counts = counts.rename(columns={x: 'normalized_count'}).reset_index()
    counts['percent'] = 100 * counts['normalized_count']
    counts['raw_count'] = list(raw_counts['raw_count'])

    plt.figure(figsize=(14, 10))
    plt.scatter(counts[x], counts[y], edgecolor='k', color='lightgreen',
                s=100 * np.sqrt(counts['raw_count']), marker='o',
                alpha=0.6, linewidth=1.5)

    if annotate:
        for i, row in counts.iterrows():
            plt.annotate(xy=(row[x] - (1 / counts[x].nunique()), row[y] - (0.15 / counts[y].nunique())),
                         color='navy', s=f"{round(row['percent'], 1)}%")

    plt.yticks(counts[y].unique())
    plt.xticks(counts[x].unique())

    sqr_min = int(np.sqrt(raw_counts['raw_count'].min()))
    sqr_max = int(np.sqrt(raw_counts['raw_count'].max()))
    msizes = list(range(sqr_min, sqr_max, int((sqr_max - sqr_min) / 5)))
    markers = []

    for size in msizes:
        markers.append(plt.scatter([], [], s=100 * size,
                                   label=f'{int(round(np.square(size) / 100) * 100)}',
                                   color='lightgreen', alpha=0.6, edgecolor='k', linewidth=1.5))

    plt.legend(handles=markers, title='Counts', labelspacing=3, handletextpad=2,
               fontsize=16, loc=(1.10, 0.19))

    plt.annotate(f'* Size represents the raw count while % is for a given y value.',
                 xy=(0, 1), xycoords='figure points', size=10)

    plt.xlim((counts[x].min() - (6 / counts[x].nunique()), counts[x].max() + (6 / counts[x].nunique())))
    plt.ylim((counts[y].min() - (4 / counts[y].nunique()), counts[y].max() + (4 / counts[y].nunique())))
    plt.grid(None)
    plt.xlabel(f"{x}")
    plt.ylabel(f"{y}")
    plt.title(f"{y} vs {x}")

# Example: Displaying the categorical strip plot
category1 = 'Years behind in school'
category2 = 'Target'

# Create a categorical strip plot
sns.catplot(x=category1, y=category2, data=train, kind='strip')
plt.show()


category1 = 'years of schooling'
category2 = 'Target'

# Create a categorical strip plot
sns.catplot(x=category1, y=category2, data=train, kind='strip')
plt.show()

plot_value_counts(data[data['Years behind in school'].isnull()], 'Target')

plot_value_counts(data[data['Monthly rent payment'].isnull()], 'Target')

id_ = ['Id', 'Household level identifier', 'Target']

ind_bool = ['=1 owns a tablet', '=1 if disable person', '=1 if male', '=1 if female', '=1 if less than 10 years old', '=1 if free or coupled uunion', '=1 if married', 
            '=1 if divorced', '=1 if separated', '=1 if widow/er', '=1 if single', 
            '=1 if household head', '=1 if spouse/partner',  '=1 if son/doughter', '=1 if stepson/doughter', '=1 if son/doughter in law', 
            '=1 if grandson/doughter', '=1 if mother/father', '=1 if father/mother in law',  '=1 if brother/sister', '=1 if brother/sister in law', 
            '=1 if other family member', '=1 if other non family member', '=1 no level of education', '=1 incomplete primary', '=1 complete primary', 
            '=1 incomplete academic secondary level', '=1 complete academic secondary level', '=1 incomplete technical secondary level', '=1 complete technical secondary level', '=1 undergraduate and higher education', 
            '=1 postgraduate higher education', '=1 if mobilephone', 'Years behind in school-missing']

ind_ordered = ['Years behind in school', 'years of schooling', 'Age in years']

hh_bool = ['=1 Overcrowding by bedrooms', '=1 Overcrowding by rooms', '=1 has a toilet in the household', '=1 if the household has a refrigerator', '=1 if predominant material on the outside wall is block or brick', '=1 if predominant material on the outside wall is socket (wood, zinc, or asbestos)', '=1 if predominant material on the outside wall is prefabricated or cement', '=1 if predominant material on the outside wall is waste material', '=1 if predominant material on the outside wall is wood', '=1 if predominant material on the outside wall is zinc', '=1 if predominant material on the outside wall is natural fibers', '=1 if predominant material on the outside wall is other', '=1 if predominant material on the floor is mosaic, ceramic, terrazzo', '=1 if predominant material on the floor is other', '=1 if predominant material on the floor is natural material', '=1 if no floor at the household', '=1 if predominant material on the floor is wood', '=1 if predominant material on the roof is metal foil or zinc', '=1 if predominant material on the roof is fiber cement, mezzanine', '=1 if predominant material on the roof is natural fibers', '=1 if predominant material on the roof is other', '=1 if the house has a ceiling', '=1 if water provision is inside the dwelling', '=1 if water provision is outside the dwelling', '=1 if no water provision', '=1 electricity from CNFL, ICE, ESPH/JASEC', '=1 electricity from a private plant', '=1 no electricity in the dwelling', '=1 electricity from a cooperative', '=1 no toilet in the dwelling', '=1 toilet connected to sewer or cesspool', '=1 toilet connected to a septic tank', '=1 toilet connected to a black hole or latrine', '=1 toilet connected to another system', '=1 no main source of energy used for cooking (no kitchen)', '=1 main source of energy used for cooking: electricity', '=1 main source of energy used for cooking: gas', '=1 main source of energy used for cooking: wood charcoal', '=1 if rubbish disposal is mainly by a tanker truck', '=1 if rubbish disposal is mainly by botan hollow or buried', '=1 if rubbish disposal is mainly by burning', '=1 if rubbish disposal is mainly by throwing in an unoccupied space', '=1 if rubbish disposal is mainly by throwing in a river, creek, or sea', '=1 if rubbish disposal is mainly other', '=1 if walls are bad', '=1 If walls are regular', '=1 if walls are good', '=1 if roofs are bad', '=1 If roofs are regular', '=1 if roofs are good', '=1 if floors are bad', '=1 If floors are regular', '=1 if floors are good', '=1 if disable person', '=1 if male', '=1 if female', '=1 if less than 10 years old', '=1 if free or coupled union', '=1 if married', '=1 if divorced', '=1 if separated', '=1 if widow/er', '=1 if single', '=1 if household head', '=1 if spouse/partner', '=1 if son/daughter', '=1 if stepson/daughter', '=1 if son/daughter-in-law', '=1 if grandson/daughter', '=1 if mother/father', '=1 if father/mother in law', '=1 if brother/sister', '=1 if brother/sister-in-law', '=1 if other family member', '=1 if other non-family member', 'Household level identifier', 'Number of children 0 to 19 in household', 'Number of adults in household', '# of individuals 65+ in the household', '# of total individuals in the household', 'Dependency rate', 'years of education of male head of household', 'years of education of female head of household', 'average years of education for adults (18+)', '=1 no level of education', '=1 incomplete primary', '=1 Complete primary', '=1 incomplete academic secondary level', '=1 complete academic secondary level', '=1 incomplete technical secondary level', '=1 complete technical secondary level', '=1 undergraduate and higher education', '=1 postgraduate higher education', 'number of bedrooms', '# persons per room', '=1 own and fully paid house', '=1 own, paying in installments', '=1 rented', '=1 precarious', '=1 other (assigned, borrowed)', '=1 if the household has a notebook or desktop computer', '=1 if the household has a TV', '=1 if mobile phone', '# of mobile phones', '=1 Region Central', '=1 Region Chorotega', '=1 Region Pacífico central', '=1 Region Brunca', '=1 Region Huetar Atlántica', '=1 Region Huetar Norte', '=1 zona urbana', '=2 zona rural', 'Age in years', 'escolari squared', 'age squared', 'hogar_total squared', 'edjefe squared', 'hogar_nin squared', 'overcrowding squared', 'dependency squared', 'meaned squared', 'Age squared']

hh_ordered = ['number of all rooms in the house', 'Males younger than 12 years of age', 'Males 12 years of age and older', 'Total males in the household', 'Females younger than 12 years of age', 'Females 12 years of age and older', 'Total females in the household', 'persons younger than 12 years of age', 'persons 12 years of age and older', 'Total persons in the household', 'number of tablets household owns', 'size of the household', 'TamViv', 'household size', 'Number of children 0 to 19 in household', 'Number of adults in household', '# of individuals 65+ in the household', '# of total individuals in the household', 'number of bedrooms', '# of mobile phones']

hh_cont = ['Monthly rent payment', 'Dependency rate', 'years of education of male head of household', 'years of education of female head of household', 'average years of education for adults (18+)', '# persons per room']


import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Read in data
train = pd.read_csv('./train.csv')
test = pd.read_csv('./test.csv')

# Define a subset of columns for the example (you can extend this list as needed)
selected_columns = ['Monthly rent payment', 'Age in years',  
                    'Total males in the household', 'Total persons in the household', 'size of the household', 
                    '=1 if predominant material on the outside wall is waste material', 
                    '=1 if no floor at the household', '=1 if the house has ceiling', '=1 no electricity in the dwelling', 
                    '=1 no main source of energy used for cooking (no kitchen)', '=1 if disable person']

# Create a subset of the data using selected columns
subset_data = train[selected_columns]

# Remove rows with missing values in the selected columns
subset_data = subset_data.dropna()

# Split the data into features and the target variable
X = subset_data.drop('Monthly rent payment', axis=1)
y = subset_data['Monthly rent payment']

# Create a Random Forest Regressor model
model = RandomForestRegressor()

# Define a dictionary of hyperparameters
param_grid = {
    'n_estimators': [10, 50, 100],
    'max_depth': [None, 10, 20],
}

# Create a GridSearchCV object
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search object to the data
grid_search.fit(X, y)

# Get the best hyperparameters
best_params = grid_search.best_params_

# Print the best hyperparameters
print("Best Hyperparameters:")
print(best_params)

# Visualize the grid search results
results = grid_search.cv_results_
max_depth_values = [None, 10, 20]
n_estimators_values = [10, 50, 100]

scores = np.array(results['mean_test_score']).reshape(len(max_depth_values), len(n_estimators_values))

plt.figure(figsize=(10, 6))
plt.imshow(scores, interpolation='nearest', cmap='viridis')
plt.xlabel('Number of Estimators')
plt.ylabel('Max Depth')
plt.colorbar()
plt.xticks(np.arange(len(n_estimators_values)), n_estimators_values)
plt.yticks(np.arange(len(max_depth_values)), max_depth_values)
plt.title('Grid Search Mean Test Scores (Negative Mean Squared Error)')
plt.show()
